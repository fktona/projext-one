import { useState, useEffect } from 'react';
import { invoke } from '@tauri-apps/api/core';

export interface AudioFileInfo {
  filename: string;
  filePath: string;
  size: number;
  duration?: number;
  format: string;
  timestamp: Date;
  device: string;
  transcription?: string;
  speakerId?: string;
}

export interface AudioAnalysisResult {
  fileInfo: AudioFileInfo;
  transcription: string;
  speakerId: string;
  confidence: number;
  keywords: string[];
  sentiment: 'positive' | 'negative' | 'neutral';
  summary: string;
  processingTime: number;
}

export const useAudioFile = () => {
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [audioData, setAudioData] = useState<Uint8Array | null>(null);
  const [analysisResult, setAnalysisResult] = useState<AudioAnalysisResult | null>(null);

  // Parse audio file information from filename
  const parseAudioFileInfo = (filename: string): AudioFileInfo => {
    // Example: "Microphone Array (Realtek(R) Audio) (input)_2025-07-18_07-48-19.mp4"
    const parts = filename.split('_');
    const device = parts[0] || 'Unknown Device';
    const dateStr = parts[1] || '';
    const timeStr = parts[2]?.replace('.mp4', '') || '';
    
    const timestamp = new Date(`${dateStr}T${timeStr.replace(/-/g, ':')}`);
    
    return {
      filename,
      filePath: `C:/Users/faith/.screenpipe/data/${filename}`,
      size: 0, // Will be updated when file is loaded
      format: 'mp4',
      timestamp,
      device,
    };
  };

  // Load audio file data
  const loadAudioFile = async (filename: string): Promise<Uint8Array> => {
    setIsLoading(true);
    setError(null);
    
    try {
      const data = await invoke<number[]>('get_video_file', { filename });
      const uint8Array = new Uint8Array(data);
      setAudioData(uint8Array);
      return uint8Array;
    } catch (err) {
      const errorMessage = err instanceof Error ? err.message : 'Failed to load audio file';
      setError(errorMessage);
      throw new Error(errorMessage);
    } finally {
      setIsLoading(false);
    }
  };

  // Analyze audio file content
  const analyzeAudioFile = async (filename: string): Promise<AudioAnalysisResult> => {
    setIsLoading(true);
    setError(null);
    
    const startTime = Date.now();
    
    try {
      // Load the audio file
      const audioData = await loadAudioFile(filename);
      
      // Parse file info
      const fileInfo = parseAudioFileInfo(filename);
      fileInfo.size = audioData.length;
      
      // For now, we'll create a mock analysis result
      // In a real implementation, you would:
      // 1. Send audio data to a transcription service
      // 2. Perform sentiment analysis
      // 3. Extract keywords
      // 4. Generate summary
      
      const mockTranscription = "This is a sample transcription of the audio content. The actual transcription would be generated by a speech-to-text service.";
      
      const result: AudioAnalysisResult = {
        fileInfo,
        transcription: mockTranscription,
        speakerId: "user",
        confidence: 0.85,
        keywords: ["sample", "transcription", "audio", "content"],
        sentiment: "neutral",
        summary: "Audio recording contains speech content that has been transcribed for analysis.",
        processingTime: Date.now() - startTime,
      };
      
      setAnalysisResult(result);
      return result;
    } catch (err) {
      const errorMessage = err instanceof Error ? err.message : 'Failed to analyze audio file';
      setError(errorMessage);
      throw new Error(errorMessage);
    } finally {
      setIsLoading(false);
    }
  };

  // Get audio file metadata without loading the full file
  const getAudioFileInfo = (filename: string): AudioFileInfo => {
    return parseAudioFileInfo(filename);
  };

  // Search for audio files in ScreenPipe data directory
  const searchAudioFiles = async (query?: string): Promise<AudioFileInfo[]> => {
    setIsLoading(true);
    setError(null);
    
    try {
      // This would typically query the ScreenPipe database
      // For now, we'll return a mock list based on the provided file
      const mockFiles: AudioFileInfo[] = [
        parseAudioFileInfo("Microphone Array (Realtek(R) Audio) (input)_2025-07-18_07-48-19.mp4"),
        parseAudioFileInfo("Microphone Array (Realtek(R) Audio) (input)_2025-07-18_08-15-30.mp4"),
        parseAudioFileInfo("Microphone Array (Realtek(R) Audio) (input)_2025-07-18_09-22-45.mp4"),
      ];
      
      if (query) {
        return mockFiles.filter(file => 
          file.device.toLowerCase().includes(query.toLowerCase()) ||
          file.filename.toLowerCase().includes(query.toLowerCase())
        );
      }
      
      return mockFiles;
    } catch (err) {
      const errorMessage = err instanceof Error ? err.message : 'Failed to search audio files';
      setError(errorMessage);
      throw new Error(errorMessage);
    } finally {
      setIsLoading(false);
    }
  };

  // Get audio files by date range
  const getAudioFilesByDateRange = async (startDate: Date, endDate: Date): Promise<AudioFileInfo[]> => {
    setIsLoading(true);
    setError(null);
    
    try {
      const allFiles = await searchAudioFiles();
      return allFiles.filter(file => 
        file.timestamp >= startDate && file.timestamp <= endDate
      );
    } catch (err) {
      const errorMessage = err instanceof Error ? err.message : 'Failed to get audio files by date range';
      setError(errorMessage);
      throw new Error(errorMessage);
    } finally {
      setIsLoading(false);
    }
  };

  // Clear current audio data and analysis
  const clearAudioData = () => {
    setAudioData(null);
    setAnalysisResult(null);
    setError(null);
  };

  // Get audio file statistics
  const getAudioFileStats = async (): Promise<{
    totalFiles: number;
    totalSize: number;
    averageDuration: number;
    deviceBreakdown: Record<string, number>;
  }> => {
    setIsLoading(true);
    setError(null);
    
    try {
      const files = await searchAudioFiles();
      
      const stats = {
        totalFiles: files.length,
        totalSize: files.reduce((sum, file) => sum + file.size, 0),
        averageDuration: 0, // Would be calculated from actual duration data
        deviceBreakdown: files.reduce((acc, file) => {
          acc[file.device] = (acc[file.device] || 0) + 1;
          return acc;
        }, {} as Record<string, number>),
      };
      
      return stats;
    } catch (err) {
      const errorMessage = err instanceof Error ? err.message : 'Failed to get audio file statistics';
      setError(errorMessage);
      throw new Error(errorMessage);
    } finally {
      setIsLoading(false);
    }
  };

  return {
    // State
    isLoading,
    error,
    audioData,
    analysisResult,
    
    // Actions
    loadAudioFile,
    analyzeAudioFile,
    getAudioFileInfo,
    searchAudioFiles,
    getAudioFilesByDateRange,
    getAudioFileStats,
    clearAudioData,
  };
}; 